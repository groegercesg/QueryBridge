{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import char\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "pd.set_option('display.float_format', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Lineitem\n",
    "\n",
    "l_columnnames = [\"L_ORDERKEY\", \"L_PARTKEY\", \"L_SUPPKEY\", \"L_LINENUMBER\", \"L_QUANTITY\", \"L_EXTENDEDPRICE\", \"L_DISCOUNT\", \"L_TAX\",\n",
    "                \"L_RETURNFLAG\", \"L_LINESTATUS\", \"L_SHIPDATE\", \"L_COMMITDATE\", \"L_RECEIPTDATE\", \"L_SHIPINSTRUCT\", \"L_SHIPMODE\", \"L_COMMENT\"]\n",
    "\n",
    "for i in range(len(l_columnnames)):\n",
    "    l_columnnames[i] = l_columnnames[i].lower()\n",
    "\n",
    "l_data_types = {\n",
    "    'l_orderkey': int,\n",
    "    'l_partkey': int,\n",
    "    'l_suppkey': int,\n",
    "    'l_linenumber': int,\n",
    "    'l_quantity': float,\n",
    "    'l_extendedprice': float,\n",
    "    'l_discount': float,\n",
    "    'l_tax': float,\n",
    "    'l_returnflag': str,\n",
    "    'l_linestatus': str,\n",
    "    'l_shipinstruct': str,\n",
    "    'l_shipmode': str,\n",
    "    'l_comment': str\n",
    "}\n",
    "\n",
    "l_parse_dates = ['l_shipdate', 'l_commitdate', 'l_receiptdate']\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "lineitem = pd.read_table(\"../../data_storage/lineitem.tbl.csv\", sep=\"|\", names=l_columnnames, dtype=l_data_types, parse_dates=l_parse_dates)\n",
    "\n",
    "# Order\n",
    "\n",
    "o_columnnames = [\"O_ORDERKEY\", \"O_CUSTKEY\", \"O_ORDERSTATUS\", \"O_TOTALPRICE\", \"O_ORDERDATE\", \"O_ORDERPRIORITY\", \"O_CLERK\", \"O_SHIPPRIORITY\", \"O_COMMENT\"]\n",
    "\n",
    "for i in range(len(o_columnnames)):\n",
    "    o_columnnames[i] = o_columnnames[i].lower()\n",
    "    \n",
    "o_data_types = {\n",
    "    'o_orderkey': int,\n",
    "    'o_custkey': int,\n",
    "    'o_orderstatus': str,\n",
    "    'o_totalprice': float,\n",
    "    'o_orderpriority': str,\n",
    "    'o_clerk': str,\n",
    "    'o_shippriority': int,\n",
    "    'o_comment': str\n",
    "}\n",
    "\n",
    "o_parse_dates = ['o_orderdate']\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "orders = pd.read_table(\"../../data_storage/orders.tbl.csv\", sep=\"|\", names=o_columnnames, dtype=o_data_types, parse_dates=o_parse_dates)\n",
    "\n",
    "# Customer\n",
    "\n",
    "c_columnnames = [\"C_CUSTKEY\", \"C_NAME\", \"C_ADDRESS\", \"C_NATIONKEY\", \"C_PHONE\", \"C_ACCTBAL\", \"C_MKTSEGMENT\", \"C_COMMENT\"]\n",
    "\n",
    "for i in range(len(c_columnnames)):\n",
    "    c_columnnames[i] = c_columnnames[i].lower()\n",
    "    \n",
    "c_data_types = {\n",
    "    'c_custkey': int,\n",
    "    'c_name': str,\n",
    "    'c_address': str,\n",
    "    'c_nationkey': int,\n",
    "    'c_phone': str,\n",
    "    'c_acctbal': float,\n",
    "    'c_mktsegment': str,\n",
    "    'c_comment': str\n",
    "}\n",
    "\n",
    "c_parse_dates = []\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "customer = pd.read_table(\"../../data_storage/customer.tbl.csv\", sep=\"|\", names=c_columnnames, dtype=c_data_types, parse_dates=c_parse_dates)\n",
    "\n",
    "# Part\n",
    "\n",
    "p_columnnames = [\"P_PARTKEY\", \"P_NAME\", \"P_MFGR\", \"P_BRAND\", \"P_TYPE\", \"P_SIZE\", \"P_CONTAINER\", \"P_RETAILPRICE\", \"P_COMMENT\"]\n",
    "\n",
    "for i in range(len(p_columnnames)):\n",
    "    p_columnnames[i] = p_columnnames[i].lower()\n",
    "    \n",
    "p_data_types = {\n",
    "    'p_partkey': int, \n",
    "    'p_name': str,\n",
    "    'p_mfgr': str,\n",
    "    'p_brand': str,\n",
    "    'p_type': str,\n",
    "    'p_size': int,\n",
    "    'p_container': str,\n",
    "    'p_retailprice': float,\n",
    "    'p_comment': str\n",
    "}\n",
    "\n",
    "p_parse_dates = []\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "part = pd.read_table(\"../../data_storage/part.tbl.csv\", sep=\"|\", names=p_columnnames, dtype=p_data_types, parse_dates=p_parse_dates)\n",
    "\n",
    "# Nation\n",
    "\n",
    "n_columnnames = [\"N_NATIONKEY\", \"N_NAME\", \"N_REGIONKEY\", \"N_COMMENT\"]\n",
    "\n",
    "for i in range(len(n_columnnames)):\n",
    "    n_columnnames[i] = n_columnnames[i].lower()\n",
    "    \n",
    "n_data_types = {\n",
    "    'n_nationkey': int,\n",
    "    'n_name': str,\n",
    "    'n_regionkey': int,\n",
    "    'n_comment': str,\n",
    "}\n",
    "\n",
    "n_parse_dates = []\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "nation = pd.read_table(\"../../data_storage/nation.tbl.csv\", sep=\"|\", names=n_columnnames, dtype=n_data_types, parse_dates=n_parse_dates)\n",
    "\n",
    "# Supplier\n",
    "\n",
    "s_columnnames = [\"S_SUPPKEY\", \"S_NAME\", \"S_ADDRESS\", \"S_NATIONKEY\", \"S_PHONE\", \"S_ACCTBAL\", \"S_COMMENT\"]\n",
    "\n",
    "for i in range(len(s_columnnames)):\n",
    "    s_columnnames[i] = s_columnnames[i].lower()\n",
    "\n",
    "s_data_types = {\n",
    "    's_suppkey': int,\n",
    "    's_name': str,\n",
    "    's_address': str,\n",
    "    's_nationkey': int,\n",
    "    's_phone': str,\n",
    "    's_acctbal': float,\n",
    "    's_comment': str\n",
    "}\n",
    "\n",
    "s_parse_dates = []\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "supplier = pd.read_table(\"../../data_storage/supplier.tbl.csv\", sep=\"|\", names=s_columnnames, dtype=s_data_types, parse_dates=s_parse_dates)\n",
    "\n",
    "# Partsupp\n",
    "\n",
    "ps_columnnames = [\"PS_PARTKEY\", \"PS_SUPPKEY\", \"PS_AVAILQTY\", \"PS_SUPPLYCOST\", \"PS_COMMENT\"]\n",
    "\n",
    "for i in range(len(ps_columnnames)):\n",
    "    ps_columnnames[i] = ps_columnnames[i].lower()\n",
    "\n",
    "ps_data_types = {\n",
    "    'ps_partkey': int,\n",
    "    'ps_suppkey': int,\n",
    "    'ps_availqty': int,\n",
    "    'ps_supplycost': float,\n",
    "    'ps_comment': str\n",
    "}\n",
    "\n",
    "ps_parse_dates = []\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "partsupp = pd.read_table(\"../../data_storage/partsupp.tbl.csv\", sep=\"|\", names=ps_columnnames, dtype=ps_data_types, parse_dates=ps_parse_dates)\n",
    "\n",
    "# Region\n",
    "\n",
    "r_columnnames = [\"R_REGIONKEY\", \"R_NAME\", \"R_COMMENT\"]\n",
    "\n",
    "for i in range(len(r_columnnames)):\n",
    "    r_columnnames[i] = r_columnnames[i].lower()\n",
    "\n",
    "r_data_types = {\n",
    "    'r_regionkey': int,\n",
    "    'r_name': str,\n",
    "    'r_comment': str\n",
    "}\n",
    "\n",
    "r_parse_dates = []\n",
    "\n",
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "region = pd.read_table(\"../../data_storage/region.tbl.csv\", sep=\"|\", names=r_columnnames, dtype=r_data_types, parse_dates=r_parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_times = []\n",
    "\n",
    "for i in range(runs):\n",
    "    start = time.time()\n",
    "\n",
    "    df_scan_1 = customer[['c_nationkey', 'c_mktsegment', 'c_custkey']]\n",
    "    df_filter_1 = df_scan_1[(df_scan_1.c_mktsegment == 'BUILDING')]\n",
    "    df_scan_2 = orders[['o_shippriority', 'o_custkey', 'o_orderdate', 'o_orderkey']]\n",
    "    df_filter_2 = df_scan_2[(df_scan_2.o_orderdate < '1995-03-15')]\n",
    "    df_scan_3 = lineitem[['l_orderkey', 'l_suppkey', 'l_linenumber', 'l_shipdate', 'l_partkey', 'l_extendedprice', 'l_discount']]\n",
    "    df_filter_3 = df_scan_3[(df_scan_3.l_shipdate > '1995-03-15')]\n",
    "    df_join_1 = df_filter_2.merge(df_filter_3, left_on=['o_orderkey'], right_on=['l_orderkey'], how='inner', sort=False)\n",
    "    df_join_2 = df_filter_1.merge(df_join_1, left_on=['c_custkey'], right_on=['o_custkey'], how='inner', sort=False)\n",
    "    df_join_2['l_extendedpricel_discount'] = df_join_2.l_extendedprice * (1 - df_join_2.l_discount)\n",
    "    df_group_1 = df_join_2 \\\n",
    "        .groupby(['l_orderkey', 'o_orderdate', 'o_shippriority'], sort=False, as_index=False) \\\n",
    "        .agg(\n",
    "            revenue=('l_extendedpricel_discount', 'sum'),\n",
    "        )\n",
    "    \n",
    "    end = time.time()\n",
    "    q3_times.append(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51389/1327582113.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n",
      "/tmp/ipykernel_51389/1327582113.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n",
      "/tmp/ipykernel_51389/1327582113.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n",
      "/tmp/ipykernel_51389/1327582113.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n",
      "/tmp/ipykernel_51389/1327582113.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n",
      "/tmp/ipykernel_51389/1327582113.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n"
     ]
    }
   ],
   "source": [
    "q6_times = []\n",
    "\n",
    "for i in range(runs):\n",
    "    start = time.time()\n",
    "\n",
    "    df_scan_1 = lineitem[['l_extendedprice', 'l_shipdate', 'l_suppkey', 'l_orderkey', 'l_discount', 'l_linenumber', 'l_partkey', 'l_quantity']]\n",
    "    df_filter_1 = df_scan_1[(df_scan_1.l_shipdate >= '1994-01-01') & (df_scan_1.l_shipdate < '1995-01-01') & (df_scan_1.l_discount >= 0.05) & (df_scan_1.l_discount <= 0.07) & (df_scan_1.l_quantity < 24)]\n",
    "    df_filter_1['mul_extended_discount'] = df_filter_1.l_extendedprice * df_filter_1.l_discount\n",
    "    df_aggr_1 = pd.DataFrame()\n",
    "    df_aggr_1['sum_mul_l_extendedprice_l_discount'] = [df_filter_1.mul_extended_discount.sum()]\n",
    "    \n",
    "    end = time.time()\n",
    "    q6_times.append(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q16_times = []\n",
    "\n",
    "for i in range(runs):\n",
    "    start = time.time()\n",
    "    \n",
    "    df_scan_1 = supplier[['s_comment', 's_nationkey', 's_suppkey']]\n",
    "    df_filter_1 = df_scan_1[df_scan_1.s_comment.str.contains('^.*?Customer.*?Compliants.*?$', regex=True)]\n",
    "    df_scan_2 = part[['p_size', 'p_brand', 'p_type', 'p_partkey']]\n",
    "    df_filter_2 = df_scan_2[df_scan_2.p_size.isin([49, 14, 23, 45, 19, 3, 36, 9]) & (df_scan_2.p_brand != 'Brand#45') & (df_scan_2.p_type.str.contains('^MEDIUM POLISHED.*?$', regex=True) == False)]\n",
    "    df_scan_3 = partsupp[['ps_suppkey', 'ps_partkey']]\n",
    "    df_join_1 = df_filter_2.merge(df_scan_3, left_on=['p_partkey'], right_on=['ps_partkey'], how='inner', sort=False)\n",
    "    df_join_2 = df_filter_1.merge(df_join_1, left_on=['s_suppkey'], right_on=['ps_suppkey'], how='outer', sort=False, indicator=True)\n",
    "    df_join_2 = df_join_2[df_join_2._merge == 'right_only'].drop('_merge', axis = 1)\n",
    "    df_group_1 = df_join_2 \\\n",
    "        .groupby(['p_brand', 'p_type', 'p_size'], sort=False, as_index=False) \\\n",
    "        .agg(\n",
    "            supplier_cnt=('ps_suppkey', lambda x : x.nunique()),\n",
    "        )\n",
    "        \n",
    "    end = time.time()\n",
    "    q16_times.append(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q21_times = []\n",
    "\n",
    "for i in range(runs):\n",
    "    start = time.time()\n",
    "    \n",
    "    df_scan_1 = nation[['n_regionkey', 'n_nationkey', 'n_name']]\n",
    "    df_filter_1 = df_scan_1[(df_scan_1.n_name == 'SAUDI ARABIA')]\n",
    "    df_scan_2 = supplier[['s_name', 's_nationkey', 's_suppkey']]\n",
    "    df_join_1 = df_filter_1.merge(df_scan_2, left_on=['n_nationkey'], right_on=['s_nationkey'], how='inner', sort=False)\n",
    "    df_scan_3 = orders[['o_custkey', 'o_orderkey', 'o_orderstatus']]\n",
    "    df_filter_2 = df_scan_3[(df_scan_3.o_orderstatus == 'F')]\n",
    "    df_scan_4 = lineitem[['l_orderkey', 'l_linenumber', 'l_suppkey', 'l_commitdate', 'l_receiptdate', 'l_partkey']]\n",
    "    df_scan_4 = df_scan_4.rename(columns={'l_orderkey': 'l_orderkey_y', 'l_suppkey': 'l_suppkey_y'})\n",
    "    df_filter_3 = df_scan_4[(df_scan_4.l_receiptdate > df_scan_4.l_commitdate)]\n",
    "    df_join_2 = df_filter_2.merge(df_filter_3, left_on=['o_orderkey'], right_on=['l_orderkey_y'], how='inner', sort=False)\n",
    "    df_join_3 = df_join_1.merge(df_join_2, left_on=['s_suppkey'], right_on=['l_suppkey_y'], how='inner', sort=False)\n",
    "    df_scan_5 = lineitem[['l_orderkey', 'l_linenumber', 'l_suppkey', 'l_partkey']]\n",
    "    df_scan_5 = df_scan_5.rename(columns={'l_orderkey': 'l_orderkey_x', 'l_suppkey': 'l_suppkey_x'})\n",
    "    inner_cond = df_join_3.merge(df_scan_5, left_on='l_orderkey_y', right_on='l_orderkey_x', how='inner', sort=False)\n",
    "    inner_cond = inner_cond[(inner_cond.l_suppkey_x != inner_cond.l_suppkey_y)]\n",
    "    df_join_4 = df_join_3[df_join_3['l_orderkey_y'].isin(inner_cond['l_orderkey_x'])]\n",
    "    df_scan_6 = lineitem[['l_orderkey', 'l_linenumber', 'l_suppkey', 'l_commitdate', 'l_receiptdate', 'l_partkey']]\n",
    "    df_filter_4 = df_scan_6[(df_scan_6.l_receiptdate > df_scan_6.l_commitdate)]\n",
    "    inner_cond = df_join_4.merge(df_filter_4, left_on='l_orderkey_y', right_on='l_orderkey', how='inner', sort=False)\n",
    "    inner_cond = inner_cond[(inner_cond.l_suppkey != inner_cond.l_suppkey_y)]['l_orderkey']\n",
    "    df_join_5 = df_join_4.merge(inner_cond, left_on=['l_orderkey_y'], right_on=['l_orderkey'], how='outer', sort=False, indicator=True)\n",
    "    df_join_5 = df_join_5[df_join_5._merge == 'left_only'].drop('_merge', axis = 1)\n",
    "    df_group_1 = df_join_5 \\\n",
    "        .groupby(['s_name'], sort=False, as_index=False) \\\n",
    "        .agg(\n",
    "            numwait=('s_name', 'count'),\n",
    "        )\n",
    "        \n",
    "    end = time.time()\n",
    "    q21_times.append(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: 0.5503345966339112\n",
      "Q6: 0.152933931350708\n",
      "Q16: 1.218865728378296\n",
      "Q21: 1.9372676372528077\n"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    (\"3\", q3_times),\n",
    "    (\"6\", q6_times),\n",
    "    (\"16\", q16_times),\n",
    "    (\"21\", q21_times)\n",
    "]\n",
    "\n",
    "def mean(array):\n",
    "    return sum(array) / len(array)\n",
    "\n",
    "for q_num, q_res in results:\n",
    "    print(f\"Q{q_num}: {mean(q_res[1:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "import csv\n",
    "with open('../test_results/duck_pandas_uplan.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['Data Type','Scaling Factor','Query Name','Query Number','Average','Correct','Executed','Runs'])\n",
    "    for q_num, q_res in results:\n",
    "        spamwriter.writerow(['Pandas','1','Pandas Converted (Duck DB)',f'Query {q_num}',str(round(mean(q_res),3)),True, \"Yes\",str(q_res)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
