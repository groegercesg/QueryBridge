{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.float_format', str)\n",
    "from datetime import date\n",
    "from numpy import char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "from tpch-pgsql-master/query_root/prep_query:\n",
    "    create_tbl.sql\n",
    "\n",
    "CREATE TABLE LINEITEM (\n",
    "    L_ORDERKEY        INTEGER NOT NULL, -- references O_ORDERKEY\n",
    "    L_PARTKEY        INTEGER NOT NULL, -- references P_PARTKEY (compound fk to PARTSUPP)\n",
    "    L_SUPPKEY        INTEGER NOT NULL, -- references S_SUPPKEY (compound fk to PARTSUPP)\n",
    "    L_LINENUMBER    INTEGER,\n",
    "    L_QUANTITY        DECIMAL,\n",
    "    L_EXTENDEDPRICE    DECIMAL,\n",
    "    L_DISCOUNT        DECIMAL,\n",
    "    L_TAX            DECIMAL,\n",
    "    L_RETURNFLAG    CHAR(1),\n",
    "    L_LINESTATUS    CHAR(1),\n",
    "    L_SHIPDATE        DATE,\n",
    "    L_COMMITDATE    DATE,\n",
    "    L_RECEIPTDATE    DATE,\n",
    "    L_SHIPINSTRUCT    CHAR(25),\n",
    "    L_SHIPMODE        CHAR(10),\n",
    "    L_COMMENT        VARCHAR(44)\n",
    ");\n",
    "\n",
    "and\n",
    "    create_idx.sql\n",
    "    \n",
    "ALTER TABLE LINEITEM ADD PRIMARY KEY (L_ORDERKEY, L_LINENUMBER);\n",
    "\"\"\"\n",
    "\n",
    "columnnames = [\"L_ORDERKEY\", \"L_PARTKEY\", \"L_SUPPKEY\", \"L_LINENUMBER\", \"L_QUANTITY\", \"L_EXTENDEDPRICE\", \"L_DISCOUNT\", \"L_TAX\", \"L_RETURNFLAG\", \"L_LINESTATUS\", \"L_SHIPDATE\", \"L_COMMITDATE\", \"L_RECEIPTDATE\", \"L_SHIPINSTRUCT\",\"L_SHIPMODE\", \"L_COMMENT\"]\n",
    "\n",
    "for i in range(len(columnnames)):\n",
    "    columnnames[i] = columnnames[i].lower()\n",
    "    \n",
    "data_types = {\n",
    "    'l_orderkey': int,\n",
    "    'l_partkey': int,\n",
    "    'l_suppkey': int,\n",
    "    'l_linenumber': int,\n",
    "    'l_quantity': float,\n",
    "    'l_extendedprice': float,\n",
    "    'l_discount': float,\n",
    "    'l_tax': float,\n",
    "    'l_returnflag': str,\n",
    "    'l_linestatus': str,\n",
    "    'l_shipinstruct': str,\n",
    "    'l_shipmode': str,\n",
    "    'l_comment': str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't set indexes, as we can't access them with Pandas selection!\n",
    "lineitem = pd.read_table(\"../../tpch-pgsql-master/data/load/lineitem.tbl.csv\", sep=\"|\", names=columnnames, dtype=data_types, parse_dates=['l_shipdate', 'l_commitdate', 'l_receiptdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             revenue\n",
      "0 123141078.22829999\n",
      "--- 0.19051766395568848 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "df_filter_1 = lineitem[(lineitem.l_shipdate >= pd.Timestamp('1994-01-01 00:00:00')) & (lineitem.l_shipdate < pd.Timestamp('1995-01-01 00:00:00')) & (lineitem.l_discount >= 0.05) & (lineitem.l_discount <= 0.07) & (lineitem.l_quantity < 24)]\n",
    "df_filter_1 = df_filter_1[['l_orderkey', 'l_partkey', 'l_suppkey', 'l_linenumber', 'l_quantity', 'l_extendedprice', 'l_discount', 'l_tax', 'l_returnflag', 'l_linestatus', 'l_shipdate', 'l_commitdate', 'l_receiptdate', 'l_shipinstruct', 'l_shipmode', 'l_comment']]\n",
    "df_aggr_1 = pd.DataFrame()\n",
    "df_aggr_1['revenue'] = [(df_filter_1.l_extendedprice * df_filter_1.l_discount).sum()]\n",
    "df_aggr_1 = df_aggr_1[['revenue']]\n",
    "df_limit_1 = df_aggr_1[['revenue']]\n",
    "end_time = time.time()\n",
    "print(df_limit_1.head(1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             revenue\n",
      "0 123141078.22829999\n",
      "--- 0.14022350311279297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Hesam / SDQL Pandas\n",
    "start_time = time.time()\n",
    "\n",
    "li_filt = lineitem[\n",
    "    (lineitem.l_shipdate >= \"1994-01-01\") &\n",
    "    (lineitem.l_shipdate < \"1995-01-01\") &\n",
    "    (lineitem.l_discount >= 0.05) &\n",
    "    (lineitem.l_discount <= 0.07) &\n",
    "    (lineitem.l_quantity < 24)\n",
    "]\n",
    "li_filt.head()\n",
    "result = pd.DataFrame()\n",
    "result['revenue'] = [(li_filt.l_extendedprice * li_filt.l_discount).sum()]\n",
    "end_time = time.time()\n",
    "print(result.head(1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!\n",
    "\n",
    "Running the command in PSQL gives the output:\n",
    "|     revenue      |\n",
    "| ---------------- |\n",
    "|  123141078.2283  |\n",
    "\n",
    "This is the same number as Pandas, so good.\n",
    "\n",
    "Time information (all times in seconds, to 3 s.f.):\n",
    "| | Run 1 | Run 2 | Run 3 | Average |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Pandas | 0.263 | 0.172 | 0.170 | 0.202 |\n",
    "| PostgreSQL | 1.28 | 1.01 | 1.07 | 1.12 |\n",
    "| Hesam Pandas | 0.148 | 0.157 | 0.152 | 0.152 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  l_returnflag l_linestatus    sum_qty    sum_base_price    sum_disc_price  \\\n",
      "0            A            F 37734107.0 56586554400.72996 53758257134.87001   \n",
      "\n",
      "         sum_charge            avg_qty          avg_price  \\\n",
      "0 55909065222.82771 25.522005853257337 38273.129734621645   \n",
      "\n",
      "              avg_disc  count_order  \n",
      "0 0.049985295838397614    1478493.0  \n",
      "--- 3.430532693862915 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "df_filter_1 = lineitem[lineitem.l_shipdate <= pd.Timestamp('1998-09-02 00:00:00')]\n",
    "df_filter_1 = df_filter_1[['l_orderkey', 'l_partkey', 'l_suppkey', 'l_linenumber', 'l_quantity', 'l_extendedprice', 'l_discount', 'l_tax', 'l_returnflag', 'l_linestatus', 'l_shipdate', 'l_commitdate', 'l_receiptdate', 'l_shipinstruct', 'l_shipmode', 'l_comment']]\n",
    "df_group_1 = df_filter_1.groupby(['l_returnflag', 'l_linestatus'])\n",
    "df_group_1 = df_group_1.apply(lambda s: pd.Series({\n",
    "    \"sum_qty\": (s[\"l_quantity\"]).sum(),\n",
    "    \"sum_base_price\": (s[\"l_extendedprice\"]).sum(),\n",
    "    \"sum_disc_price\": (s[\"l_extendedprice\"] * ( 1 - s[\"l_discount\"] )).sum(),\n",
    "    \"sum_charge\": (( s[\"l_extendedprice\"] * ( 1 - s[\"l_discount\"] )) * ( 1 + s[\"l_tax\"] )).sum(),\n",
    "    \"avg_qty\": (s[\"l_quantity\"]).mean(),\n",
    "    \"avg_price\": (s[\"l_extendedprice\"]).mean(),\n",
    "    \"avg_disc\": (s[\"l_discount\"]).mean(),\n",
    "    \"count_order\": len(s.index),\n",
    "}))\n",
    "df_group_1 = df_group_1[['sum_qty', 'sum_base_price', 'sum_disc_price', 'sum_charge', 'avg_qty', 'avg_price', 'avg_disc', 'count_order']]\n",
    "df_sort_1 = df_group_1.sort_values(by=['l_returnflag', 'l_linestatus'], ascending=[True, True])\n",
    "df_sort_1 = df_sort_1[['sum_qty', 'sum_base_price', 'sum_disc_price', 'sum_charge', 'avg_qty', 'avg_price', 'avg_disc', 'count_order']]\n",
    "df_limit_1 = df_sort_1.rename_axis(['l_returnflag', 'l_linestatus']).reset_index()\n",
    "df_limit_1 = df_limit_1[['l_returnflag', 'l_linestatus', 'sum_qty', 'sum_base_price', 'sum_disc_price', 'sum_charge', 'avg_qty', 'avg_price', 'avg_disc', 'count_order']]\n",
    "end_time = time.time()\n",
    "print(df_limit_1.head(1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54437/1387439186.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  li_filt[\"disc_price\"] = li_filt.l_extendedprice * (1 - li_filt.l_discount)\n",
      "/tmp/ipykernel_54437/1387439186.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  li_filt[\"charge\"] = li_filt.l_extendedprice * (1 - li_filt.l_discount) * (1 + li_filt.l_tax)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sum_qty  sum_base_price  sum_disc_price  \\\n",
      "l_returnflag l_linestatus                                              \n",
      "A            F            37734107.0  56586554400.73  53758257134.87   \n",
      "\n",
      "                                 sum_charge  count_order  \n",
      "l_returnflag l_linestatus                                 \n",
      "A            F            55909065222.82769      1478493  \n",
      "--- 2.1302566528320312 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Query from SDQL.py\n",
    "li_filt = lineitem[(lineitem.l_shipdate <= \"1998-09-02\")]\n",
    "li_filt[\"disc_price\"] = li_filt.l_extendedprice * (1 - li_filt.l_discount)\n",
    "li_filt[\"charge\"] = li_filt.l_extendedprice * (1 - li_filt.l_discount) * (1 + li_filt.l_tax)\n",
    "\n",
    "result = li_filt \\\n",
    "    .groupby([\"l_returnflag\", \"l_linestatus\"]) \\\n",
    "    .agg(\n",
    "        sum_qty=(\"l_quantity\", \"sum\"),\n",
    "        sum_base_price=(\"l_extendedprice\", \"sum\"),\n",
    "        sum_disc_price=(\"disc_price\", \"sum\"),\n",
    "        sum_charge=(\"charge\", \"sum\"),\n",
    "        count_order=(\"l_quantity\", \"count\")\n",
    "    )\n",
    "    \n",
    "df_sort = result.sort_values(by=['l_returnflag', 'l_linestatus'], ascending=[True, True])\n",
    "end_time = time.time()\n",
    "print(df_sort.head(1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!\n",
    "\n",
    "Running the command in PSQL gives the output:\n",
    "\n",
    "| l_returnflag | l_linestatus | sum_qty | sum_base_price | sum_disc_price | sum_charge | avg_qty | avg_price | avg_disc | count_order |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| A | F | 37734107 | 56586554400.73 | 53758257134.8700 | 55909065222.827692 | 25.5220058532573370 | 38273.129734621672 | 0.04998529583839761162 | 1478493 |\n",
    "\n",
    "\n",
    "This is **ROUGHLY** (See below) the same numbers as Pandas, so good.\n",
    "\n",
    "Time information (all times in seconds, to 3 s.f.):\n",
    "| | Run 1 | Run 2 | Run 3 | Average |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Pandas | 3.53 | 4.70 | 3.81 | 4.01 |\n",
    "| PostgreSQL | 5.99 | 6.22 | 6.30 | 6.17 |\n",
    "| Hesam Pandas | 2.06 | 2.67 | 2.13 | 2.29 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Issue\n",
    "\n",
    "The rounding in Pandas and PostgreSQL might (and on initial inspection looks to be)\n",
    "\n",
    "*TODO:* Investigate Pandas and PostgreSQL datatypes, potentially look at schema\n",
    "\n",
    "\n",
    "\n",
    "Column Datatypes Comparison:\n",
    "\n",
    "| Postgres Type | Specifications | Pandas Type | Specifications |\n",
    "| --- | --- | --- | --- |\n",
    "| INTEGER | -2147483648 to +2147483647 | int64 | -9223372036854775808 to 9223372036854775807 |\n",
    "| DECIMAL | 131072 digits before the decimal point; 16383 after  | float64 | Double precision float: sign bit, 11 bits exponent, 52 bits mantissa |\n",
    "| CHAR(1) | fixed-length, blank padded | str | arrays of bytes representing Unicode characters |\n",
    "| DATE | 4 bytes, date (no time of day) | datetime64[ns] | it represents an offset from 1970-01-01T00:00:00 |\n",
    "| VARCHAR | variable-length with limit | str | arrays of bytes representing Unicode characters |\n",
    "\n",
    "Let's look at \"sum_base_price\", in Postgres this is: _56586554400.73_ but in Pandas this is: _56586554400.72996_\n",
    "\n",
    "\"sum_base_price\" is created from summing *l_extendedprice* (DECIMAL) in Postgres, through: *sum(l_extendedprice)*\n",
    "And in Pandas, it's created by again summing *l_extendedprice* (float), through: *(s[\"l_extendedprice\"]).sum()*\n",
    "\n",
    "Is this a difference in how they are displayed?\n",
    "In pandas, we have already set the display format for floats to be a string, for readability\n",
    "\n",
    "**CONCLUSION**\n",
    "This is fine, we if they're at least up to 5 (or n) significant figures of accuracy then that's completely okay."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
